""""""
"""
重点是 机器学习基本理论
"""

"""
机器学习是AI的一个子领域, 核心是通过数据驱动, 让计算机进行学习并改进性能, 自动发现规律（模式）, 并利用这些规律进行预测或决策.
"""

"""
机器学习的方法一般主要由三部分构成：模型、策略和算法
    
    机器学习方法 = 模型 + 策略 + 算法
    
* 模型（model）：总结数据的内在规律, 用数学语言描述的参数系统
* 策略（strategy）：选取最优模型的评价准则
* 算法（algorithm）：选取最优模型的具体方法
"""

"""
机器学习分类：
    有监督学习：提供数据并提供数据对应结果的机器学习过程
    无监督学习：提供数据并且不提供数据对应结果的机器学习过程
    强化学习：通过与环境交互并获取延迟返回进而改进行为的学习过程
"""

"""
监督学习建模的整体流程：
    1. 收集数据：收集用于训练和测试的数据集, 确保数据代表了实际问题的不同方面
    2. 数据清洗：对数据进行清洗, 去除掉一些脏数据和不可用的数据
    3. 特征工程：对数据进行转换和格式化, 以确保它适用于机器学习模型训练
    4. 选择算法：选择适合任务类型（分类、回归、聚类等）和数据特征的机器学习算法
    5. 模型训练：使用训练数据集来训练模型, 让模型从数据中学习规律或模式
    6. 模型评估：使用测试数据集评估模型的性能, 确定其是否达到了预期的目标
    7. 模型优化：在确保模型具有较好性能的基础上, 进一步提高模型的效果
    8. 模型部署：将训练好的模型部署到生产环境中, 并实时监控其表现
"""

"""
特征工程：
    是机器学习过程中非常重要的一步, 指的是通过对原始数据的处理、转换和构造, 生成新的特征或选择有效的特征, 从而提高模型的性能.
    特征工程是将原始数据转换为可以更好地表示问题的特征形式, 帮助模型更好地理解和学习数据中的规律.
    优秀的特征工程可以显著提高模型的表现; 反之, 忽视特征工程可能导致模型性能欠佳.
"""

"""
特征工程的内容：

特征选择：从原始特征中挑选出与目标变量关系最密切的特征, 剔除冗余、无关或噪声特征. 这样可以减少模型的复杂度、加速训练过程、并减少过拟合的风险.
    1. 过滤法
    2. 包裹法
    3. 嵌入法
    
特征转换：对数据进行数学或统计处理, 使其变得更加适合模型的输入要求
    1. 归一化
    2. 标准化
    3. 对数变换
    4. 类别变量的编码
    
特征构造：特征构造是基于现有的特征创造出新的、更有代表性的特征. 通过组合、转换、或者聚合现有的特征, 形成能够更好反映数据规律的特征.
    1. 交互特征
    2. 统计特征
    3. 日期与时间特征
    
特征降维：当数据集的特征数量非常大时, 特征降维可以帮助减少计算复杂度并避免过拟合. 通过降维方法, 可以在保持数据本质的情况下减少特征的数量.
    1. 主成分分析
    2. 线性判别分析
    3. t-SNE（t-Distributed Stochastic Neighbor Embedding, t分布随机近邻嵌入）
    4. 自编码器
"""

"""
模型评估与模型选择（重点）

1. 损失函数
    对于监督学习而言, 给定一个输入X, 选取的模型就相当于一个 '决策函数' f, 它可以输出一个预测结果 f(X), 而真实的结果（标签）记为 Y.
    f(X) 和 Y 之间可能会有误差, 我们就用一个损失函数（loss function）来度量预测偏差的程度, 记作 L(Yf(X))
    
    * 损失函数用来衡量模型预测误差的大小; 损失函数值越小, 模型就越好
    * 损失函数是 f(X) 和 Y 的非负实数函数
    
    1）0-1损失函数
        L(Y,f(X))={ 1,  Y!=f(X)
                  { 0,  Y=f(X) 
    2）平方损失函数
        L(Y,f(X))=(Y-f(X))^2
    3）绝对损失函数
        L(Y,f(X))=|Y-f(X)|
    4）对数似然损失函数
        L(Y,P(Y|X))=-logP(Y|X)
        

2. 经验误差
    给定一个训练数据集, 数据个数为 n:
        T={(x_1,y_1),(x_2,y_2),…,(x_n,y_n)}
    根据选取的损失函数, 就可以计算出模型 f(X) 在训练集上的平均误差, 称为训练误差, 也被称作 经验误差（empirical error）或经验风险（empirical risk）
    
    类似地, 在测试数据集上平均误差, 被称为测试误差或者 泛化误差（generalization error）
    一般情况下对模型评估的策略, 就是考察经验误差; 当经验风险最小时, 就认为取到了最优的模型. 这种策略被称为 经验风险最小化（empirical risk minimization, ERM）


3. 欠拟合与过拟合
    拟合（Fitting）：是指机器学习模型在训练数据上学习到规律并生成预测结果的过程。理想情况下, 模型能够准确地捕捉训练数据的模式, 并且在未见过的新数据（测试数据）上也有良好的表现; 即模型具有良好的泛化能力.
    欠拟合（Underfitting）：是指模型在训练数据上表现不佳, 无法很好地捕捉数据中的规律. 这样的模型不仅在训练集上表现不好, 在测试集上也同样表现差.
    过拟合（Overfitting）：是指模型在训练数据上表现得很好, 但在测试数据或新数据上表现较差的情况. 过拟合的模型对训练数据中的噪声或细节过度敏感, 把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质, 从而失去了泛化能力.
    
    产生的根本原因：
        * 欠拟合：模型在训练集和测试集上误差都比较大. 模型过于简单, 高偏差.
        * 过拟合：模型在训练集上误差较小, 但在测试集上误差较大. 模型过于复杂, 高方差.
        
    产生原因与解决方法：
        欠拟合：
            产生原因：
                * 模型复杂度不足：模型过于简单, 无法捕捉数据中的复杂关系
                * 特征不足：输入特征不充分, 或者特征选择不恰当, 导致模型无法充分学习数据的模式
                * 训练不充分：训练过程中迭代次数太少, 模型没有足够的学习数据的规律
                * 过强的正则化：正则化项设置过大, 强制模型过于简单, 导致模型无法充分拟合数据
            解决办法：
                * 增加模型复杂度：选择更复杂的模型
                * 增加特征或改进特征工程：添加更多的特征或通过特征工程来创造更有信息量的特征
                * 增加训练时间：增加训练的迭代次数, 让模型又更多机会去学习
                * 减少正则化强度：如果使用了正则化, 尝试减小正则化的权重, 以让模型更灵活
        过拟合：
            产生原因：
                * 模型复杂度过高：模型过于复杂, 参数太多
                * 训练数据不足：数据集太小, 模型能记住训练数据的细节, 但无法泛化到新数据
                * 特征过多：特征太多, 模型可能会“记住”数据中的噪声, 而不是学到真正的规律
                * 训练过长：训练时间过长, 导致模型学习到训练数据中的噪声, 而非数据的真正规律
            解决办法：
                * 减少模型复杂度：降低模型的参数数量、使用简化的模型或降维来减少模型复杂度
                * 增加训练数据：收集更多数据, 或通过数据增强来增加训练数据的多样性
                * 使用正则化：引入L1、L2正则化, 避免过度拟合训练数据
                * 交叉验证：使用交叉验证技术评估模型在不同数据集上的表现, 以减少过拟合的风险
                * 早停：训练时, 当模型的验证损失不再下降时, 提前停止训练, 避免过度拟合训练集

    
"""
